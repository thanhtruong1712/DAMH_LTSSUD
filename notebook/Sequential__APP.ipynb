{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m0rrV7EHEV0G",
        "BTY7aCF0PSjK",
        "ZCyWHKBTgI8Z",
        "JRoIVrWUivDA",
        "i6dMJkT8Lxlf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Đồ án môn học \"Lập trình song song ứng dụng\"\n",
        "\n",
        "# Xác định loại bệnh thực vật bằng phương pháp trích xuất dữ liệu và mô hình XGBoost.\n",
        "\n",
        "## Giảng viên: Phạm Trọng Nghĩa\n",
        "\n",
        "### Nhóm 14:\n",
        "- 1712771 - Bùi Thái Tấn Thành\n",
        "- 1712770 - Trương Thị Lệ Thanh\n"
      ],
      "metadata": {
        "id": "3CE3Rl9trdXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chạy file:** tải thủ công 1 hình (test 4) vào file này."
      ],
      "metadata": {
        "id": "8Co_3NfrKneh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "J-mZpgJbJKEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from numba import njit, jit, cuda\n",
        "import math\n",
        "test_image = cv.imread('/content/images/Test_4.jpg')"
      ],
      "metadata": {
        "id": "1PRjZ6Rmuw4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533f6dbb-c738-4d9a-971e-5374c5df2ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Eg_0c3mvQCu0SpVjLdik1-g1Tuz22ObS\n",
            "To: /content/plant-pathology-2020-fgvc7.zip\n",
            "100% 817M/817M [00:07<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U xgboost==1.5.1 numba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "xmOTpaJRUHMa",
        "outputId": "35d97fcf-3bc6-4ad5-c9fb-cce60d6265ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.5.1\n",
            "  Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 173.5 MB 8.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.51.2)\n",
            "Collecting numba\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.5.1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.5.1) (1.4.1)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n",
            "Installing collected packages: llvmlite, xgboost, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.38.1 numba-0.55.2 xgboost-1.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llvmlite",
                  "numba"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cài đặt tuần tự"
      ],
      "metadata": {
        "id": "1BogiZKmRI_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert color"
      ],
      "metadata": {
        "id": "kBhS_4r_RDwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### gray"
      ],
      "metadata": {
        "id": "uAFO3VBkERUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def convert_rgb2gray(in_pixels, out_pixels):\n",
        "    '''\n",
        "    Convert color image to grayscale image.\n",
        "    in_pixels : numpy.ndarray with shape=(h, w, 3)\n",
        "                h, w is height, width of image\n",
        "                3 is colors with BGR (blue, green, red) order\n",
        "        Input RGB image\n",
        "    \n",
        "    out_pixels : numpy.ndarray with shape=(h, w)\n",
        "        Output image in grayscale\n",
        "    '''\n",
        "    for r in range(len(in_pixels)):\n",
        "        for c in range(len(in_pixels[0])):\n",
        "            out_pixels[r, c] = round(in_pixels[r, c, 0] * 0.114 + \n",
        "                                in_pixels[r, c, 1] * 0.587 + \n",
        "                                in_pixels[r, c, 2] * 0.299)\n",
        "    return out_pixels"
      ],
      "metadata": {
        "id": "gi6jQr_RRGIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_gray = np.empty(test_image.shape[:2])"
      ],
      "metadata": {
        "id": "zC6vx01OSjP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "img_gray = convert_rgb2gray(test_image, img_gray)"
      ],
      "metadata": {
        "id": "8vV2vaDXRScJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cv_gray = cv.cvtColor(test_image, cv.COLOR_BGR2GRAY)"
      ],
      "metadata": {
        "id": "BDEpIk8bStbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.abs(cv_gray - img_gray).mean()"
      ],
      "metadata": {
        "id": "kCnFK992TCMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### hsv"
      ],
      "metadata": {
        "id": "m0rrV7EHEV0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`BGR2HSV`: \n",
        "-  Biểu diễn cách màu sắc xuất hiện dưới ánh sáng\n",
        "- H - Hue (Bước sóng ưu thế).\n",
        "- S - Độ bão hòa (Độ tinh khiết / sắc thái của màu).\n",
        "- V - Giá trị (Cường độ ánh sáng).\n",
        "\n",
        "Cài đặt theo openCV: https://learnopencv.com/color-spaces-in-opencv-cpp-python/"
      ],
      "metadata": {
        "id": "DVbuP0zvEYP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def convert_bgr2hsv(in_pixels, out_pixels):\n",
        "    '''\n",
        "    3d & 3d\n",
        "    '''\n",
        "    for i in range(len(in_pixels)):\n",
        "        for j in range(len(in_pixels[0])):\n",
        "            b,g,r = in_pixels[i,j,0]/255,in_pixels[i,j,1]/255,in_pixels[i,j,2]/255\n",
        "            S=0\n",
        "            H=0\n",
        "            V = max(r,g,b)\n",
        "            if V!=0:\n",
        "                S=round((V-min(r,g,b))/V ,3)\n",
        "            if r==g and g==b:\n",
        "                H=0\n",
        "            elif V==r:\n",
        "                H= 60*(g-b)/(V-min(r,g,b))\n",
        "            elif V==g:\n",
        "                H= 120 + 60*(b-r)/(V-min(r,g,b))\n",
        "            else:\n",
        "                H= 240 + 60*(r-g)/(V-min(r,g,b))\n",
        "            if H<0:\n",
        "                H = H + 360\n",
        "            out_pixels[i,j,0] = round(H/2,0)\n",
        "            out_pixels[i,j,1] =  round(255*S,0)\n",
        "            out_pixels[i,j,2] = 255*V\n",
        "    return out_pixels\n",
        "\n",
        "img=cv.imread('/content/images/Test_4.jpg')\n",
        "o_img =img.copy()\n",
        "c2 = convert_bgr2hsv(img,o_img)\n",
        "\n",
        "img=cv.imread('/content/images/Test_4.jpg')\n",
        "c1 = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "\n",
        "print(\"----------------error----------\")\n",
        "np.mean(np.abs(c2.astype(np.float32)- c1.astype(np.float32))) # up low"
      ],
      "metadata": {
        "id": "QlW3w2fp6ql0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv.imread('/content/images/Test_4.jpg')\n",
        "o_img =img.copy()"
      ],
      "metadata": {
        "id": "yeFU3EQhGr9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "c2 = convert_bgr2hsv(img,o_img)"
      ],
      "metadata": {
        "id": "wV0eN9k9GtRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GaussianBlur"
      ],
      "metadata": {
        "id": "BTY7aCF0PSjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gaussian_kernel(ksize, sigma):\n",
        "    '''\n",
        "    Hàm tạo bộ lọc Gaussian có kích thước shape x shape với các giá trị có độ lệch chuẩn sigma.\n",
        "\n",
        "    Đầu vào:\n",
        "    - ksize (int): kích thước bộ lọc\n",
        "    - sigma (float): độ lệch chuẩn.\n",
        "\n",
        "    Đầu ra:\n",
        "    - kernel (np.array): bộ lọc Gaussian\n",
        "\n",
        "    Tham khảo:\n",
        "    https://stackoverflow.com/questions/8204645/implementing-gaussian-blur-how-to-calculate-convolution-matrix-kernel\n",
        "    https://github.com/opencv/opencv/blob/4.x/modules/imgproc/src/smooth.dispatch.cpp\n",
        "    '''\n",
        "    if ksize == 1:\n",
        "        kernel = np.array([1.])\n",
        "    elif ksize == 3:\n",
        "        kernel = np.array([0.25, 0.5, 0.25])\n",
        "    elif ksize == 5:\n",
        "        kernel = np.array([0.0625, 0.25, 0.375, 0.25, 0.0625])\n",
        "    elif ksize == 7:\n",
        "        kernel = np.array([0.03125, 0.109375, 0.21875, 0.21875, 0.21875, 0.109375, 0.03125])\n",
        "    else:\n",
        "        if sigma <= 0:\n",
        "            sigma = 0.3 * ((ksize - 1) * 0.5 - 1) + 0.8\n",
        "\n",
        "        G = lambda x: math.exp(-(x - (ksize - 1) / 2)**2 / (2 * sigma**2))\n",
        "        kernel = np.array([G(x) for x in range(ksize)])\n",
        "        kernel /= kernel.sum()\n",
        "\n",
        "    return kernel\n",
        "\n",
        "@njit\n",
        "def apply_kernel(image, kernel):\n",
        "    '''\n",
        "    Hàm thực hiện phép tích chập 2 chiều giữa ảnh image và bộ lọc kernel.\n",
        "    Tại vùng biên, phần tử lân cận gần nhất được chọn làm phần tử đệm.\n",
        "    Độ dời khi duyệt là 1.\n",
        "\n",
        "    Đầu vào:\n",
        "    - image (np.array): ảnh đầu vào.\n",
        "    - kernel (np.array): bộ lọc\n",
        "\n",
        "    Đầu ra:\n",
        "    - out (np.array): ảnh đã được áp dụng bộ lọc.\n",
        "    '''\n",
        "    image = np.atleast_3d(image)\n",
        "    offset = (kernel.shape[0] // 2, kernel.shape[1] // 2)\n",
        "    last_row = image.shape[0] - 1\n",
        "    last_col = image.shape[1] - 1\n",
        "\n",
        "    out = np.zeros_like(image, np.uint8)\n",
        "    out_pixel = np.zeros(image.shape[-1], np.float32)\n",
        "\n",
        "    for out_r in range(image.shape[0]):\n",
        "        for out_c in range(image.shape[1]):\n",
        "            for filter_r, r in enumerate(range(out_r - offset[0], out_r + offset[0] + 1)):\n",
        "                for filter_c, c in enumerate(range(out_c - offset[1], out_c + offset[1] + 1)):\n",
        "                    in_r = min(max(0, r), last_row)\n",
        "                    in_c = min(max(0, c), last_col)\n",
        "\n",
        "                    out_pixel += image[in_r, in_c] * kernel[filter_r, filter_c]\n",
        "\n",
        "            out[out_r, out_c] = np.floor(out_pixel).astype(np.uint8)\n",
        "            out_pixel -= out_pixel\n",
        "\n",
        "    return out\n",
        "\n",
        "def create_gaussian_filter(ksize, sigmaX, sigmaY=0):\n",
        "    '''\n",
        "    Hàm tạo bộ lọc Gauss\n",
        "\n",
        "    Đầu vào:\n",
        "    - ksize (tuple): kích thước bộ lọc Gauss, thể hiện số dòng, số cột.\n",
        "    - sigmaX, sigmaY (float): độ lệch chuẩn cho giá trị bộ lọc theo chiều dọc và ngang.\n",
        "\n",
        "    Đầu ra\n",
        "    - kernel (np.array): bộ lọc Gauss\n",
        "    '''\n",
        "    kernel_x = get_gaussian_kernel(ksize[0], sigmaX)\n",
        "    kernel_x = np.expand_dims(kernel_x, 1)\n",
        "\n",
        "    if sigmaY == 0:\n",
        "        sigmaY = sigmaX\n",
        "    kernel_y = get_gaussian_kernel(ksize[1], sigmaY)\n",
        "    kernel_y = np.expand_dims(kernel_y, 0)\n",
        "\n",
        "    return kernel_x @ kernel_y\n",
        "\n",
        "def gaussian_blur(image, ksize, sigmaX, sigmaY=0):\n",
        "    '''\n",
        "    Hàm làm mờ ảnh sử dụng bộ lọc Gauss.\n",
        "\n",
        "    Đầu vào:\n",
        "    - image (np.array): ảnh đầu vào.\n",
        "    - ksize (tuple): kích thước bộ lọc Gauss, thể hiện số dòng, số cột.\n",
        "    - sigmaX, sigmaY (float): độ lệch chuẩn cho giá trị bộ lọc theo chiều dọc và ngang.\n",
        "\n",
        "    Đầu ra\n",
        "    - blur (np.array): ảnh kết quả sau khi áp dụng bộ lọc\n",
        "    '''\n",
        "    kernel = create_gaussian_filter(ksize, sigmaX, sigmaY)\n",
        "\n",
        "    out = apply_kernel(image, kernel)\n",
        "    if len(image.shape) != len(out.shape):\n",
        "        out.shape = image.shape\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "skQoW-P3Pe3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "img_blur = gaussian_blur(cv_gray, (3,3), 0)"
      ],
      "metadata": {
        "id": "w6IRVxOIQJ5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cv_blur = cv.GaussianBlur(cv_gray, (3, 3), 0)"
      ],
      "metadata": {
        "id": "US83Yx6dUcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.abs(img_blur - cv_blur).mean()"
      ],
      "metadata": {
        "id": "2WgeH_G4UmaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fd_histogram"
      ],
      "metadata": {
        "id": "ZCyWHKBTgI8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "trong hàm `fd_histogram` có sử dụng [`BGR2HSV`](#scrollTo=DVbuP0zvEYP-&line=5&uniqifier=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "kMk74KRVGL-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fd_histogram(image):\n",
        "    bins = 8\n",
        "    # convert the image to HSV color-space\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
        "\n",
        "    # compute the color histogram\n",
        "    hist  = cv.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
        "\n",
        "    # normalize the histogram\n",
        "    cv.normalize(hist, hist)\n",
        "\n",
        "    # return the histogram\n",
        "    return hist.ravel()"
      ],
      "metadata": {
        "id": "EMJGcnoHgMMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def compute_hist(img, hist):\n",
        "    '''\n",
        "    Color histogram: thống kê số lần xuất hiện các mức sáng trong ảnh với bins=8, \n",
        "                     phạm vi [0,255] cho mỗi kênh màu\n",
        "    input: \n",
        "            img: numpy.ndarray with shape=(h, w, 3)\n",
        "            hist: numpy.ndarray with shape=(8,8,8)\n",
        "    '''\n",
        "    h, w = img.shape[:2] \n",
        "    for i in range(h): \n",
        "        for j in range(w): \n",
        "            x,y,z=img[i][j][0]//32,img[i][j][1]//32,img[i][j][2]//32\n",
        "            hist[x][y][z] =hist[x][y][z] + 1 \n",
        "    return hist\n",
        "\n",
        "def fd_histogram2(image, mask=None):\n",
        "    # convert the image to HSV color-space\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
        "\n",
        "    # compute the color histogram\n",
        "    hist = np.zeros((8,8,8), np.float32) \n",
        "    hist  = compute_hist(image,hist)\n",
        "\n",
        "    # normalize the histogram\n",
        "    cv.normalize(hist, hist)\n",
        "    hist=hist\n",
        "    # return the histogram\n",
        "    return hist.ravel()"
      ],
      "metadata": {
        "id": "Wcwcw7YQiNsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cv_hist_figure = fd_histogram(cv.imread('/content/Test_4.jpg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0DEwJ1IiQ3M",
        "outputId": "8e3044d3-0b75-4620-f5a6-6ae3b4ec4631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 54.2 ms, sys: 3.06 ms, total: 57.3 ms\n",
            "Wall time: 67.5 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "hist_figure = fd_histogram2(cv.imread('/content/Test_4.jpg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr8wVPxCieYb",
        "outputId": "4e726eaa-cabd-46de-a150-d5c22a432815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
            "Wall time: 433 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.abs(cv_hist_figure.astype(np.float64)- hist_figure).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCYnp9glik4D",
        "outputId": "5f39c84a-d0d2-4fc7-f5a9-887aa818cc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_figure.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWvKkjMtSGRj",
        "outputId": "d62cf4d1-5771-4cd0-f907-05b3aa42d631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0098800175"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=cv.imread('/content/images/Test_4.jpg')\n",
        "hist21 = np.zeros((8,8,8), np.float32) "
      ],
      "metadata": {
        "id": "IR4w4B6CRy9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "hist21  = compute_hist(temp,hist21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bskcHXx_HUsH",
        "outputId": "fdc32aa2-75ae-4f62-f258-f4afefac8398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.3 ms, sys: 913 µs, total: 10.2 ms\n",
            "Wall time: 10.9 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fd_hu_moments"
      ],
      "metadata": {
        "id": "JRoIVrWUivDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fd_hu_moments(gray_image):\n",
        "    # image = cv.cvtColor(gray_image, cv.COLOR_BGR2GRAY)\n",
        "    feature = cv.HuMoments(cv.moments(gray_image)).ravel()\n",
        "    return feature"
      ],
      "metadata": {
        "id": "DJCWaM_fi1eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def cvMoments(img,m_,mu_,nu_):\n",
        "    '''\n",
        "    input:  ảnh 2D\n",
        "        m_ mảng 3x3 : M ~ raw Moments\n",
        "        mu_ 3x3: mu ~ central moments\n",
        "        nu_ 3x3: nu ~ normalized central moments \n",
        "    output: nu_\n",
        "    '''\n",
        "    # tính m_\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            temp=0\n",
        "            if (i,j) not in [(1,3),(2,2),(2,3)]:\n",
        "                for x in range(img.shape[0]):\n",
        "                    for y in range(img.shape[1]):\n",
        "                        temp=temp+img[x,y]*(x**i)*(y**j)\n",
        "                m_[i,j]=temp\n",
        "            if i==3:\n",
        "                break\n",
        "\n",
        "    # xbar ybar\n",
        "    xbar=m_[1,0]/m_[0,0]\n",
        "    ybar=m_[0,1]/m_[0,0]\n",
        "\n",
        "    # tính mu\n",
        "    mu_[1,1] = m_[1,1] - xbar*m_[0,1]\n",
        "    mu_[0,2] = m_[2,0] - xbar*m_[1,0]\n",
        "    mu_[2,0] = m_[0,2] - ybar*m_[0,1]\n",
        "    mu_[1,2] = m_[2,1] - 2*xbar*m_[1,1] - ybar*m_[2,0] + 2*(xbar**2)*m_[0,1]\n",
        "    mu_[2,1] = m_[1,2] - 2*ybar*m_[1,1] - xbar*m_[0,2] + 2*(ybar**2)*m_[1,0]\n",
        "    mu_[0,3] = m_[3,0] - 3*xbar*m_[2,0] + 2*(xbar**2)*m_[1,0]\n",
        "    mu_[3,0] = m_[0,3] - 3*ybar*m_[0,2] + 2*(ybar**2)*m_[0,1]\n",
        "\n",
        "    #tính nu  nu_ji = mu_ji / [m00^(((i+j)/2)+1)]\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            nu_[i,j] = mu_[i,j]/(m_[0,0]**(((i+j)/2)+1))\n",
        " \n",
        "    return nu_\n",
        "\n",
        "# HuMoments\n",
        "@njit\n",
        "def cvHuMoments(eta,hu_):\n",
        "    '''\n",
        "    eta: output của cvMoments\n",
        "    hu_: Mảng 1D 7 giá trị \n",
        "    '''\n",
        "    hu_[0] =  eta[2][0] + eta[0][2]\n",
        "    hu_[1] = (eta[2][0] - eta[0][2])**2 + 4*eta[1][1]**2\n",
        "    hu_[2] = (eta[3][0] - 3*eta[1][2])**2 + (3*eta[2][1] - eta[0][3])**2\n",
        "    hu_[3] = (eta[3][0] + eta[1][2])**2 + (eta[2][1] + eta[0][3])**2\n",
        "    hu_[4] = (eta[3][0] - 3*eta[1][2])*(eta[3][0] + eta[1][2])*((eta[3][0] + eta[1][2])**2 - 3*(eta[2][1] + eta[0][3])**2) +\\\n",
        "                (3*eta[2][1] - eta[0][3])*(eta[2][1] + eta[0][3])*(3*(eta[3][0] + eta[1][2])**2 - (eta[2][1] + eta[0][3])**2)\n",
        "\n",
        "    hu_[5] = (eta[2][0] - eta[0][2])*((eta[3][0] + eta[1][2])**2 - (eta[2][1] + eta[0][3])**2) + \\\n",
        "          4*eta[1][1]*(eta[3][0] + eta[1][2])*(eta[2][1] + eta[0][3])\n",
        "\n",
        "    hu_[6] = (3*eta[2][1] - eta[0][3])*(eta[2][1] + eta[0][3])*(3*(eta[3][0] + eta[1][2])**2-(eta[2][1] + eta[0][3])**2) -\\\n",
        "          (eta[3][0] - 3*eta[1][2])*(eta[1][2] + eta[0][3])*(3*(eta[3][0] + eta[1][2])**2-(eta[2][1] + eta[0][3])**2)\n",
        "\n",
        "    return hu_\n",
        "\n",
        "def fd_hu_moments2(gray_image):\n",
        "    m=np.zeros((4, 4), dtype=np.float64)\n",
        "    mu=np.zeros((4, 4), dtype=np.float64)\n",
        "    nu=np.zeros((4, 4), dtype=np.float64)\n",
        "    hu=np.zeros(7,np.float64)\n",
        "\n",
        "    feature = cvHuMoments(cvMoments(gray_image, m, mu, nu), hu)\n",
        "    return feature"
      ],
      "metadata": {
        "id": "AZuYstewjJ06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_gray = cv.cvtColor(cv.imread('/content/images/Test_4.jpg'), cv.COLOR_BGR2GRAY)"
      ],
      "metadata": {
        "id": "EXY7hrObNhqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cv_hu_moments = fd_hu_moments(cv_gray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLWRL2InjVSX",
        "outputId": "dca931a3-7dbd-48cc-fdf7-ac04c55a554d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.07 ms, sys: 1.03 ms, total: 3.1 ms\n",
            "Wall time: 7.12 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(cv_hu_moments[0])"
      ],
      "metadata": {
        "id": "fjb2KXOIejqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "hu_moments = fd_hu_moments2(cv_gray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b560a159-9305-41ec-bc10-049478535bca",
        "id": "nQxfBVdRjhhW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.24 s, sys: 18 ms, total: 2.26 s\n",
            "Wall time: 2.27 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.abs(cv_hu_moments - hu_moments).mean()"
      ],
      "metadata": {
        "id": "DQ8dJetSjk6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nén và lấp khuyết"
      ],
      "metadata": {
        "id": "i6dMJkT8Lxlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def zipImage(src, zip_x, zip_y, ratio):\n",
        "    rs, cs = src.shape\n",
        "    zip_rs = int(rs / zip_y)\n",
        "    zip_cs = int(cs / zip_x)\n",
        "    for idx in range(0, zip_rs * zip_y, zip_y):\n",
        "        for jdx in range(0, zip_cs * zip_x, zip_x):\n",
        "            block_img = src[idx : idx + zip_y, jdx : jdx + zip_x]\n",
        "            num_pixel = np.sum(block_img > 0)\n",
        "            if num_pixel >= zip_x*zip_y * ratio:\n",
        "                block_img[:,:] = 1\n",
        "            else:\n",
        "                block_img[:,:] = 0\n",
        "\n",
        "    return src\n",
        "\n",
        "@jit\n",
        "# Hàm dùng để liên kết các ô xung quanh để lấp khuyết sẽ trả ra kết quả là một ma trận mask\n",
        "def joinNeiboorPixel(src, zip_x, zip_y, mask_size, ratio):\n",
        "    rs, cs = src.shape\n",
        "    zip_rs = int(rs / zip_y)\n",
        "    zip_cs = int(cs / zip_x)\n",
        "    half = int(mask_size / 2)\n",
        "    dst = src.copy()\n",
        "    for idx in range(half , zip_rs - half):\n",
        "        for jdx in range(half, zip_cs - half):\n",
        "            start_row_mask = (idx - half ) * zip_y\n",
        "            end_row_mask = (idx + half + 1) * zip_y\n",
        "            start_col_mask = (jdx - half) * zip_x\n",
        "            end_col_mask = (jdx + half + 1) * zip_x\n",
        "            mask_block = src[start_row_mask : end_row_mask, start_col_mask : end_col_mask]\n",
        "            block_img = dst[idx * zip_y : (idx + 1) * zip_y, jdx * zip_x : (jdx + 1) * zip_x]\n",
        "            num_pixel = np.sum(mask_block > 0)\n",
        "            if num_pixel >= mask_size * mask_size * zip_x * zip_y * ratio:\n",
        "                block_img[:,:] = 1\n",
        "    return dst"
      ],
      "metadata": {
        "id": "b-vLfcSiL13z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    img = cv.imread('/content/images/Test_4.jpg')\n",
        "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    gray = cv.GaussianBlur(gray, (3, 3), 0)"
      ],
      "metadata": {
        "id": "P7Qf84_PMZz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mask_img = zipImage(gray, 16, 16, 0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g4g63BOMgM-",
        "outputId": "87b436f4-2976-4c4c-90fe-f77e38cde2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 977 ms, sys: 20.3 ms, total: 998 ms\n",
            "Wall time: 996 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mask_img = joinNeiboorPixel(mask_img, 8, 8, 3, 0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18IhdX2BMjXk",
        "outputId": "fc0c0beb-e67f-4c6d-ed63-dc6ed6051f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 737 ms, sys: 7.16 ms, total: 744 ms\n",
            "Wall time: 767 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm duyệt cây"
      ],
      "metadata": {
        "id": "yo60KnCFAlpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5h_woA60XA-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array, empty_like, empty, int32, float64, zeros\n",
        "from math import exp\n",
        "from queue import Queue\n",
        "import json\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "yRVC-5-6DRKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def softmax(arr:array):\n",
        "    result = empty_like(arr)\n",
        "    nrows, ncols = arr.shape\n",
        "\n",
        "    for i in range(nrows):\n",
        "        row_sum = 0\n",
        "        for j in range(ncols):\n",
        "            element_exp = exp(arr[i, j])\n",
        "            result[i, j] = element_exp\n",
        "            row_sum += element_exp\n",
        "\n",
        "        for j in range(ncols):\n",
        "            result[i, j] /= row_sum\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def load_tree(feature_arr:array, value_arr:array, tree_dict:dict):\n",
        "    '''\n",
        "    Hàm đọc cấu trúc cây ở dạng từ điển.\n",
        "    Kết quả đọc được lưu vào mảng đặc trưng và giá trị truyền vào.\n",
        "\n",
        "    Đầu vào:\n",
        "    - feature_arr, value_arr (numpy.array): mảng lưu đặc trưng và giá trị của các nút trong cây\n",
        "    - tree_dict (dict): thông tin về cây quyết định lưu ở dạng từ điển\n",
        "    '''\n",
        "    # tạo hàng đợi FIFO các nút và chỉ mục tương ứng trong mảng\n",
        "    tree_q = Queue()\n",
        "    tree_q.put(tree_dict)\n",
        "\n",
        "    idx_q = Queue()\n",
        "    idx_q.put(0)\n",
        "\n",
        "    while not tree_q.empty():\n",
        "        node = tree_q.get()\n",
        "        idx = idx_q.get()\n",
        "\n",
        "        # xác định nút lá hay nút nhánh\n",
        "        # nếu có khóa 'leaf' là nút lá\n",
        "        node_val = node.get('leaf')\n",
        "        if node_val is None:\n",
        "            # lưu đặc trưng và giá trị ngưỡng phân nhánh\n",
        "            feature_arr[idx] = int32(node['split'][1:])\n",
        "            value_arr[idx] = float64(node['split_condition'])\n",
        "\n",
        "            # thêm vào hàng đợi thông tin và chỉ mục trong mảng của nút con\n",
        "            tree_q.put(node['children'][0])\n",
        "            tree_q.put(node['children'][1])\n",
        "\n",
        "            idx_q.put(2 * idx + 1)\n",
        "            idx_q.put(2 * idx + 2)\n",
        "        else:\n",
        "            feature_arr[idx] = -1 # giá trị đặc biệt thể hiện nút lá\n",
        "            value_arr[idx] = float64(node_val)\n",
        "\n",
        "\n",
        "def load_model(hyperparams_path:str, tree_path:str):\n",
        "    '''\n",
        "    Hàm đọc mô hình XGBoost đã lưu.\n",
        "    Mỗi cây trong mô hình được lưu thành mảng 1 chiều bao gồm 2 mảng đặc trưng và giá trị.\n",
        "    Mảng giá trị thê hiện giá trị phân nhánh hoặc nút lá tùy giá trị đặc trưng tại ô tương ứng.\n",
        "\n",
        "    Đầu vào:\n",
        "    - hyperparams_path, tree_path (str): lần lượt là đường dẫn tới tập tin lưu các siêu tham số\n",
        "    và lưu cấu trúc cây của mô hình.\n",
        "\n",
        "    Đầu ra:\n",
        "    - n_estimators (int): số (nhóm) cây thành phần của mô hình.\n",
        "    - n_classes (int): số phân lớp đã huấn luyện\n",
        "    - features (numpy.array): mảng thể hiện đặc trưng được xét tại nút trong cây.\n",
        "    - values (numpy.array): mảng thể hiện giá trị phân nhánh hoặc nút lá.\n",
        "    '''\n",
        "    # mở tập tin, phân tích cú pháp và lưu thông tin vào từ điển\n",
        "    with open(hyperparams_path) as f:\n",
        "        hyperparams = json.load(f)\n",
        "\n",
        "    with open(tree_path) as f:\n",
        "        tree_list = json.load(f)\n",
        "\n",
        "    # truy xuất các siêu tham số\n",
        "    attributes = json.loads(hyperparams['learner']['attributes']['scikit_learn'])\n",
        "    n_estimators = attributes['n_estimators']\n",
        "    n_classes = attributes['n_classes_']\n",
        "    max_depth = attributes['max_depth']\n",
        "    if max_depth is None:\n",
        "        max_depth = 6\n",
        "\n",
        "    # xác định số nút tối đa của cây thành phần và tạo mảng.\n",
        "    nrows = len(tree_list)\n",
        "    ncols = sum((2**i for i in range(max_depth+1)))\n",
        "    features = empty((nrows, ncols), int32)\n",
        "    values = empty((nrows, ncols), float64)\n",
        "\n",
        "    # đọc và nạp thông tin các cây vào mảng\n",
        "    for feat_arr, val_arr, tree in zip(features, values, tree_list):\n",
        "        load_tree(feat_arr, val_arr, tree)\n",
        "\n",
        "    return n_estimators, n_classes, features, values\n",
        "\n",
        "@njit\n",
        "def traverse_tree(x:array, features_arr:array, values_arr:array):\n",
        "    '''\n",
        "    Hàm duyệt cây quyết định và đưa ra dự đoán chon một đối tượng.\n",
        "\n",
        "    Đầu vào:\n",
        "    - x (numpy.array): đối tượng dự đoán.\n",
        "    - features_arr, values_arr (numpy.array): mảng đặc trưng và giá trị của cây quyết định.\n",
        "\n",
        "    Đầu ra:\n",
        "    - value (float): giá trị dự đoán.\n",
        "    '''\n",
        "    idx = 0\n",
        "\n",
        "    # kiểm tra nút lá\n",
        "    while features_arr[idx] != -1:\n",
        "        # so sánh giá trị đặc trưng của đối tượng và giá trị phân nhánh\n",
        "        # duyệt tới nút con phù hợp.\n",
        "        if x[features_arr[idx]] - values_arr[idx] < 0:\n",
        "            idx = 2 * idx + 1\n",
        "        else:\n",
        "            idx = 2 * idx + 2\n",
        "\n",
        "    return values_arr[idx]\n",
        "\n",
        "@njit\n",
        "def predict_proba(X:array, features_arr:array, values_arr:array, n_classes:int32):\n",
        "    '''\n",
        "    Hàm dự đoán tập dữ liệu trên mô hình XGBoost được đọc.\n",
        "\n",
        "    Đầu vào:\n",
        "    - X (numpy.array): tập dữ liệu dự đoán.\n",
        "    - features_arr, values_arr (numpy.array): mảng đặc trưng và giá trị của cây quyết định.\n",
        "    - n_classes (int): số phân lớp được huấn luyện.\n",
        "\n",
        "    Đầu ra:\n",
        "    - y_pred (numpy.array): mảng dự đoán xác suất thuộc về các phân lớp của các đối tượng\n",
        "    '''\n",
        "    y_pred = zeros((X.shape[0], n_classes))\n",
        "\n",
        "    for i, x in enumerate(X):\n",
        "        for j, (f_arr, v_arr) in enumerate(zip(features_arr, values_arr)):\n",
        "            y_pred[i, j % n_classes] += traverse_tree(x, f_arr, v_arr)\n",
        "\n",
        "    return softmax(y_pred)"
      ],
      "metadata": {
        "id": "gr1IiKlnAlHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators, n_classes, features, values = load_model('/content/xgb_hyperparams.json', '/content/xgb_tree.json')\n",
        "X_test = np.load('/content/X_test.npy')"
      ],
      "metadata": {
        "id": "z8ptNhNDDUB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgblib_model = XGBClassifier(objective='multi:softmax', use_label_encoder=False,\n",
        "                                                    num_class=n_classes, n_estimators=n_estimators, learning_rate=0.2)\n",
        "\n",
        "xgblib_model.load_model('/content/xgb_hyperparams.json')"
      ],
      "metadata": {
        "id": "pZEwt5VMD7Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgblib_pred = xgblib_model.predict(X_test)"
      ],
      "metadata": {
        "id": "qImqqvwLEAt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "xgb_pred = np.argmax(predict_proba(X_test, features, values, n_classes), 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beee96c6-83cd-4f8f-83e3-7dc925d01c32",
        "id": "p9s7dcHrMpuz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 45.4 ms, sys: 750 µs, total: 46.1 ms\n",
            "Wall time: 46 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.count_nonzero(xgblib_pred != xgb_pred)"
      ],
      "metadata": {
        "id": "u6_LspFPERN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Độ chính xác & thời gian"
      ],
      "metadata": {
        "id": "5SbIMfWxXCln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Hàm | Sai số |Thời gian |Ghi chú |\n",
        "|:--------:|:-----------:|:-----------:|:-----------:|\n",
        "|rgb2gray  |  1.43e-06 |  413 ms |  | \n",
        "| GBR2HSV  | 0.025|65.1 ms|  Không sử dụng| \n",
        "| GaussianBlur  |  108.53 | 2.36 s |  Không sử dụng | \n",
        "| Histogram  | 0 | 343 ms|  | \n",
        "| huMoments  | 2.32e-23 | 2.27 s | | \n",
        "| duyệt cây  | |  46 ms|   | \n",
        "| zipImage  |  | 996 ms |   | \n",
        "| joinNeiboorPixel  |  | 767 ms |   | \n",
        "\n",
        "**Ghi chú**: ô trống là tự cài đặt từ đầu.\n"
      ],
      "metadata": {
        "id": "tkFuVpY5XSv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tài liệu tham khảo\n",
        "- https://towardsdatascience.com/using-nmf-to-classify-companies-a77e176f276f\n",
        "- https://github.com/jonasrothfuss/fishervector\n",
        "- https://hal.inria.fr/hal-00779493/file/RR-8209.pdf\n",
        "- https://viblo.asia/p/sift-scale-invariant-feature-transform-huan-luyen-mo-hinh-cho-cac-bai-toan-phan-loai-924lJqJaZPM\n",
        "- https://xgboost.readthedocs.io/en/stable/\n",
        "- https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
        "- https://medium.com/analytics-vidhya/what-makes-xgboost-so-extreme-e1544a4433bb"
      ],
      "metadata": {
        "id": "Jf3ich6DBLpS"
      }
    }
  ]
}